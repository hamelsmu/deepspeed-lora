{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "328c49e2-ea9e-4e94-abd3-bf88b4eb0358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp run_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800091ef-d45f-45f1-a864-d210b9fb2b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from fastcore.script import call_parse, Param, store_true\n",
    "from random import randint\n",
    "import os, subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea139d6-3965-4478-9236-872f64ea246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def gen_cli(debug:Param('Print command instead of running it', store_true),\n",
    "            ds_stg:Param('The deepspeed stage', int, choices=[0,3])=3,\n",
    "            n_gpu:Param('number of GPUs', int, choices=[1,2,3])=1,\n",
    "            gc:Param('Toggle gradient checkpointing', choices=['True', 'False'])='True',  \n",
    "            seq_len:Param('Sequence length', int, choices=[64, 256, 512, 1024, 2048])=256,\n",
    "            bs:Param('Batch size', int, choices=[1,3,4,6,8,16,32, 64,100, 128, 200, 256])=1,\n",
    "            model_sz:Param('Model size in Billions', int, choices=[3, 7, 13, 34])=7,\n",
    "            n_epochs:Param('# of epochs', int) = 1,\n",
    "           ):\n",
    "    \"Generate Training CLI Command\"\n",
    "\n",
    "    model_id = {3:'pankajmathur/orca_mini_3b', 7:'NousResearch/Llama-2-7b-hf', 13: 'NousResearch/Llama-2-13b-hf', 34: 'NousResearch/CodeLlama-34b-hf'}[model_sz]\n",
    "    nr = randint(10000000,99999999)\n",
    "    env_values = [('WANDB_ENTITY', 'hamelsmu'), ('WANDB_PROJECT', 'deepspeed-data'),\n",
    "                  ('WANDB_RUN_ID', f'z{ds_stg}-n_gpu{n_gpu}-gc{gc}-seq_len{seq_len}-bs{bs}-model_sz{model_sz}-{nr}')]\n",
    "    env_str = ''\n",
    "    for v in env_values:\n",
    "        env_str  += f'{v[0]}={v[1]} '\n",
    "    \n",
    "    cmd = f\"\"\"torchrun --nproc_per_node {n_gpu} run_lora.py \\\n",
    "  --model_id {model_id} \\\n",
    "  --dataset_path data_{seq_len} \\\n",
    "  --output_dir {model_id}-fa \\\n",
    "  --num_train_epochs {n_epochs} \\\n",
    "  --per_device_train_batch_size {bs} \\\n",
    "  --learning_rate 4e-3 \\\n",
    "  --gradient_checkpointing {gc} \\\n",
    "  --bf16 True \\\n",
    "  --tf32 True \\\n",
    "  --lr_scheduler_type constant_with_warmup \\\n",
    "  --logging_steps 25 \\\n",
    "  --report_to \"wandb\" \\\n",
    "  --deepspeed z{ds_stg}.json\"\"\"\n",
    "\n",
    "    full_cmd = env_str + ' ' + cmd\n",
    "\n",
    "    if debug:\n",
    "        print(full_cmd)\n",
    "    else:\n",
    "        env_vars = os.environ.copy()\n",
    "        for v in env_values:\n",
    "            env_vars[v[0]] = v[1]\n",
    "        print(f\"running command:\\n{full_cmd}\")\n",
    "        return subprocess.run(cmd.split(), env=env_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33740129-9df9-4285-93fd-d995cd7df844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import nb_export\n",
    "nb_export('run_bench.ipynb', lib_path='.', name='run_bench')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "817a4a83-b1bd-497e-8f87-76a0c73f1a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: run_bench.py [-h] [--debug] [--ds_stg {0,3}] [--n_gpu {1,2,3}]\n",
      "                    [--gc {True,False}] [--seq_len {64,256,512,1024,2048}]\n",
      "                    [--bs {1,3,4,6,8,16,32,64,100,128,200,256}]\n",
      "                    [--model_sz {3,7,13,34}] [--n_epochs N_EPOCHS]\n",
      "\n",
      "Generate Training CLI Command\n",
      "\n",
      "options:\n",
      "  -h, --help                            show this help message and exit\n",
      "  --debug                               Print command instead of running it\n",
      "                                        (default: False)\n",
      "  --ds_stg {0,3}                        The deepspeed stage (default: 3)\n",
      "  --n_gpu {1,2,3}                       number of GPUs (default: 1)\n",
      "  --gc {True,False}                     Toggle gradient checkpointing (default:\n",
      "                                        True)\n",
      "  --seq_len {64,256,512,1024,2048}      Sequence length (default: 256)\n",
      "  --bs {1,3,4,6,8,16,32,64,100,128,200,256}\n",
      "                                        Batch size (default: 1)\n",
      "  --model_sz {3,7,13,34}                Model size in Billions (default: 7)\n",
      "  --n_epochs N_EPOCHS                   # of epochs (default: 1)\n"
     ]
    }
   ],
   "source": [
    "!python run_bench.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0b3eb7-c4a8-403c-b1ac-8ab294ade0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDB_ENTITY=hamelsmu WANDB_PROJECT=deepspeed-data WANDB_RUN_ID=z3-n_gpu3-gcTrue-seq_len1024-bs8-model_sz3-50751264  torchrun --nproc_per_node 3 run_lora.py   --model_id pankajmathur/orca_mini_3b   --dataset_path data_1024   --output_dir pankajmathur/orca_mini_3b-fa   --num_train_epochs 1   --per_device_train_batch_size 8   --learning_rate 4e-3   --gradient_checkpointing True   --bf16 True   --tf32 True   --lr_scheduler_type constant_with_warmup   --logging_steps 25   --report_to \"wandb\"   --deepspeed z3.json\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python run_bench.py --ds_stg 3 --n_gpu 3 --gc True \\\n",
    "--seq_len 1024 --bs 8 --model_sz 3 --debug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
