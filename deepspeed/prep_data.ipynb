{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d1f902-441d-4f0f-a9f1-48e21f7f80e2",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934cb7ea-18b2-438a-aaa5-63615d8226ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamel/mambaforge/envs/deepspeed-lora/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "from random import randint\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "from transformers import AutoTokenizer\n",
    "from fastcore.script import call_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52175e53-4ca5-4da1-95c1-606fab8bf84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-hf\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a6aac3-b04c-49b7-bb47-6ca03c935ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def format_dolly(sample):\n",
    "    instruction = f\"### Instruction\\n{sample['instruction']}\"\n",
    "    context = f\"### Context\\n{sample['context']}\" if len(sample[\"context\"]) > 0 else None\n",
    "    response = f\"### Answer\\n{sample['response']}\"\n",
    "    # join all the parts together\n",
    "    prompt = \"\\n\\n\".join([i for i in [instruction, context, response] if i is not None])\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{format_dolly(sample)}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    from datasets import load_dataset\n",
    "    dataset = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train\")\n",
    "    return dataset.map(template_dataset, remove_columns=list(dataset.features))\n",
    "\n",
    "\n",
    "def chunk(sample, chunk_length=2048):\n",
    "    # define global remainder variable to save remainder from batches to use in next batch\n",
    "    global remainder\n",
    "    # Concatenate all texts and add remainder from previous batch\n",
    "    concatenated_examples = {k: list(chain(*sample[k])) for k in sample.keys()}\n",
    "    concatenated_examples = {k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()}\n",
    "    # get total number of tokens for batch\n",
    "    batch_total_length = len(concatenated_examples[list(sample.keys())[0]])\n",
    "\n",
    "    # get max number of chunks for batch\n",
    "    if batch_total_length >= chunk_length:\n",
    "        batch_chunk_length = (batch_total_length // chunk_length) * chunk_length\n",
    "\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_length] for i in range(0, batch_chunk_length, chunk_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # add remainder to global variable for next batch\n",
    "    remainder = {k: concatenated_examples[k][batch_chunk_length:] for k in concatenated_examples.keys()}\n",
    "    # prepare labels\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b4be76-8d9e-4acd-9640-47daa94ccbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "remainder = {\"input_ids\": [], \"attention_mask\": [], \"token_type_ids\": []}\n",
    "\n",
    "def generate(seq_len, n=1024, dsname=None):\n",
    "    dataset = get_data()\n",
    "    lm_dataset = dataset.map(\n",
    "        lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(dataset.features)\n",
    "            ).map(\n",
    "                partial(chunk, chunk_length=seq_len),\n",
    "                batched=True).select(range(n))\n",
    "    if dsname:\n",
    "        lm_dataset.save_to_disk(dsname)\n",
    "    return lm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f61c1ee-8a2d-4378-b452-846071426c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dataset = generate(2048, n=256)\n",
    "assert len(lm_dataset[0]['input_ids']) == 2048\n",
    "assert len(lm_dataset) == 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cfcf1b8-ca37-4044-bdee-089013d3b8b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:00<00:00, 457211.29 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:00<00:00, 76589.93 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15011/15011 [00:01<00:00, 7568.56 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 800/800 [00:00<00:00, 66829.52 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15011/15011 [00:01<00:00, 7648.20 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 400/400 [00:00<00:00, 35954.00 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15011/15011 [00:02<00:00, 7487.46 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 18977.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "data_configs = [\n",
    "    {'seq_len': 64, 'n': 3000, 'dsname': 'data_64'},\n",
    "    {'seq_len': 256, 'n': 1600, 'dsname': 'data_256'},\n",
    "    {'seq_len': 512, 'n': 800, 'dsname': 'data_512'},\n",
    "    {'seq_len': 1024, 'n': 400, 'dsname': 'data_1024'},\n",
    "    {'seq_len': 2048, 'n': 200, 'dsname': 'data_2048'}\n",
    "]\n",
    "\n",
    "for d in data_configs:\n",
    "    generate(**d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea2521-e3a3-4210-b2c5-e354a9e07746",
   "metadata": {},
   "source": [
    "# Prepare Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9929604d-f028-416a-bd53-aa6ddd3f56bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192000\n",
      "409600\n",
      "409600\n",
      "409600\n",
      "409600\n"
     ]
    }
   ],
   "source": [
    "for d in data_configs:\n",
    "    print(d['seq_len'] * d['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52219255-4ef6-48bc-9482-2712fe7eeb02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
